{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Word Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fabianbeigang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/fabianbeigang/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases, Word2Vec\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data from YouGov/SE\n",
    "with open('data/preprocessed_sentences_se_and_trusted.json', 'r') as f:\n",
    "    preprocessed_sentences_se_and_trusted = json.load(f)\n",
    "\n",
    "# Load p# Load preprocessed data from CAM\n",
    "with open('data/preprocessed_sentences_pseudoscience.json', 'r') as f:\n",
    "    preprocessed_sentences_pseudoscience = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE and Trusted Sources:\n",
      "['riley', 'year_token', 'antimicrobial', 'activity', 'major', 'component', 'essential', 'oil', 'rare_token', 'rare_token']\n",
      "['mode', 'antimicrobial', 'action', 'essential', 'oil', 'rare_token', 'rare_token', 'tea', 'tree', 'oil']\n",
      "['study', 'minimum', 'inhibitory', 'concentration', 'mode', 'action', 'oregano', 'essential', 'oil', 'transition', 'pore', 'inner', 'mitochondrial', 'membrane', 'operate', 'open', 'state', 'different', 'selectivity']\n",
      "\n",
      "Pseudoscience:\n",
      "['disease']\n",
      "['patient', 'rare_token', 'muscle', 'contract', 'tic', 'rare_token', 'face', 'usually', 'left']\n",
      "['individual', 'control', 'spasm', 'occur', 'asleep']\n"
     ]
    }
   ],
   "source": [
    "# Print the first three sentences for each\n",
    "print(\"SE and Trusted Sources:\")\n",
    "for sent in preprocessed_sentences_se_and_trusted[:3]:\n",
    "    print(sent)\n",
    "print()\n",
    "print(\"Pseudoscience:\")\n",
    "for sent in preprocessed_sentences_pseudoscience[:3]:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and extract unigram and bigram phrases\n",
    "bigram_transformer = Phrases(preprocessed_sentences_se_and_trusted+preprocessed_sentences_pseudoscience, min_count=100, threshold=20) \n",
    "bigram_sentences_se_trusted = [bigram_transformer[s] for s in preprocessed_sentences_se_and_trusted]\n",
    "bigram_sentences_pseudoscience = [bigram_transformer[s] for s in preprocessed_sentences_pseudoscience]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE/Trusted: {'tea_tree', 'essential_oil', 'primary_secondary', 'human_papilloma', 'creative_common', 'url_token', 'faculty_member', 'sustainable_development', 'sexually_transmit', 'national_institute', 'broad_range', 'semi_structured', 'inclusion_criterion', 'rare_token', 'islamic_republic', 'year_token', 'maternal_neonatal', 'num_token', 'mode_action'}\n",
      "Pseudoscience: {'nervous_system', 'calcium_magnesium', 'rare_token', 'john_wort', 'leave_untreated', 'blood_clotting', 'blood_vessel', 'green_leafy', 'regular_basis', 'botulinum_toxin', 'graphene_oxide', 'cranial_nerve', 'pfizer_moderna', 'polyethylene_glycol', 'johnson_johnson', 'num_token', 'middle_aged'}\n"
     ]
    }
   ],
   "source": [
    "# Print example phrases for both corpora\n",
    "print(f\"SE/Trusted: {set([word for sublist in bigram_sentences_se_trusted[:50] for word in sublist if '_' in word])}\")\n",
    "print(f\"Pseudoscience: {set([word for sublist in bigram_sentences_pseudoscience[:50] for word in sublist if '_' in word])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bigram_transformer vocab\n",
    "with open('data/bigram_transformer_vocab.json', 'w') as f:\n",
    "    json.dump(bigram_transformer.vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train word2vec word vector embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters (parameters based on Rodriguez and Spirling, 2021)\n",
    "vector_size = 300 #before: 50\n",
    "window = 6 # before: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model for SE and YouGov corpus\n",
    "model_se_trusted = Word2Vec(bigram_sentences_se_trusted, vector_size=vector_size, window=window, min_count=5, workers=4)\n",
    "model_se_trusted.save(\"word2vec_with_bigrams_se_trusted_300_6.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model for CAM corpus\n",
    "model_pseudoscience = Word2Vec(bigram_sentences_pseudoscience, vector_size=vector_size, window=window, min_count=5, workers=4)\n",
    "model_pseudoscience.save(\"word2vec_with_bigrams_pseudoscience_300_6.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
